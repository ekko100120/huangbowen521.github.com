<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Cloud | 黄博文的地盘]]></title>
  <link href="http://www.huangbowen.net/blog/categories/cloud/atom.xml" rel="self"/>
  <link href="http://www.huangbowen.net/"/>
  <updated>2014-07-26T18:56:59+10:00</updated>
  <id>http://www.huangbowen.net/</id>
  <author>
    <name><![CDATA[黄博文]]></name>
    <email><![CDATA[huangbowen521@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[AWS系列之二  使用EC2]]></title>
    <link href="http://www.huangbowen.net/blog/2014/07/26/using-ec2/"/>
    <updated>2014-07-26T18:27:22+10:00</updated>
    <id>http://www.huangbowen.net/blog/2014/07/26/using-ec2</id>
    <content type="html"><![CDATA[<p>在本文中我们有三个任务。
第一：使用Amazon management console创建一个EC2实例。
第二：使用本地的命令行工具远程登陆到该EC2实例。
第三：在该EC2实例上创建一个web服务，并通过公共域名来访问该web服务。</p>

<!-- more -->


<p>如果你还没有AWS的账号的话，可以使用qwiklabs提供的免费实验来进行该练习。地址是<a href="https://run.qwiklabs.com">https://run.qwiklabs.com</a>。</p>

<p>登陆到亚马逊的AWS服务的management console后选择EC2服务。</p>

<p>{% img /images/awsdashboard.png 700 %}</p>

<p>然后你就可以到EC2的控制面板了。</p>

<p>{% img /images/ec2dashboard.png 700 %}</p>

<p>点击上面大大的<code>Launch Instance</code>按钮来开始创建一个新的EC2实例。</p>

<p>{%img /images/imagetype.png 700 %}</p>

<p>首先要选择机器的镜像文件AMI（Amazon Machine Image）,有各种Linux的发行版，也有Windows系统。在本次实验中我们选取第一个，即Amazon Linux AMI，亚马逊自己的一个Linux发行版。</p>

<p>然后是选择机器类型，不同类型机器性能不同，收费标准也不一样，一切都是根据你的需求来决定。就选第一个吧，最便宜。</p>

<p>{%img /images/instancetype.png 700 %}</p>

<p>然后你有两个选择，一个是点击<code>Review and Launch</code>直接启动新机器，其余参数都采用默认值，另一个是点击<code>Next:Configure Instance Details</code>自定义其它配置。在这里我们选择第二个按钮，然后直到step6：Configure Security Group。</p>

<p>{% img /images/scrole.png 700 %}</p>

<p>这里是配置安全组的，你可以使用已有的安全组，也可以创建一个全新的安全组。在安全组里可以设置一系列策略来管理该实例与外界的访问情况。</p>

<p>由于我们需要远程登录到该实例，并且需要该实例提供http服务，所以我们需要开放22和80端口。22端口默认是开放的，80端口则需要手动开放。方法是点击<code>Add Role</code>按钮并新加一个role。</p>

<p>{% img /images/httprole.png 700 %}</p>

<p>配置完成后点击<code>Launch</code>按钮，会弹出一个页面让你设置key pair。</p>

<p>{% img /images/keypairconfiguration.png 700 %}</p>

<p>这个key pair是用来与该实例建立安全连接。亚马逊会存一个公钥，自己在本地存放一个私钥，当想要连接该实例时，需要提供私钥。这里我们选择新建一个key pair，并取名为awsworkshop，选择保存到本地。稍后会使用它来ssh到该实例。</p>

<p>点击<code>Launch Instances</code>按钮，实例就会被初始化了。</p>

<p>{% img /images/launchstatus.png 700 %}</p>

<p>点击<code>View Instances</code>来查看新创建的实例。</p>

<p>{% img /images/ec2information.png 700 %}</p>

<p>一般需要等待3到5分钟来完成对新实例的初始化。在上图中可以查看该实例的相关信息。亚马逊给该实例分配了一个公共IP和公共DNS域名，稍后需要使用它们。</p>

<p>等到该实例的<code>Instance Status</code>为<code>running</code>后，我们就可以进行第二个任务了，就是远程连接到该实例。</p>

<p>打开你心爱的终端，然后先提升刚保存的pem文件的权限。</p>

<pre><code class="bash">

$: chmod 600 ~/Downloads/awsworkshop.pem
</code></pre>

<p>然后在AWS的控制面板上找到该实例的公共IP，使用ec2-user用户名来ssh到该实例。</p>

<pre><code class="bash">

$: ssh ec2-user@54.191.210.210 -i ~/Downloads/awsworkshop.pem
</code></pre>

<p>稍微等待以后就可以连接到远程实例了。</p>

<pre><code class="bash">

[ec2-user@ip-172-31-46-246 ~]$ who
ec2-user pts/0        2014-07-26 06:38 (123-243-183-184.static.tpgi.com.au) 
</code></pre>

<p>怎么样？一切都非常简单吧？</p>

<p>下面就进行这个实验的最后一个任务了，在该远程实例上搭建一个web服务器。</p>

<p>ssh到该实例后，执行下面命令。</p>

<pre><code class="bash">

$: sudo yum install httpd
</code></pre>

<p>这句命令是安装Apache的httpd服务器。</p>

<p>然后跳转到<code>/var/www/html</code>目录下，并新建一个名为<code>index.html</code>的文件。</p>

<pre><code class="bash">
$: cd /var/www/html
$: sudo touch index.html
</code></pre>

<p>使用你习惯的编辑器在该文件中输入一个html格式的文档并保存。</p>

<pre><code class="html">
&lt;html&gt;
    &lt;body&gt;
        &lt;h1&gt;Hello World!&lt;/h1&gt;
    &lt;/body&gt;
&lt;html&gt;
</code></pre>

<p>接下来启动web服务器。</p>

<pre><code class="bash">
$: sudo service httpd start
</code></pre>

<p>大功告成，从该EC2实例的控制面板中找到其公共DNS，然后粘贴到浏览器中，就可以访问其提供的web服务了。</p>

<p>{%img /images/website.png 700 %}</p>

<p>好了，这三个任务也就都完成了。希望大家喜欢这次EC2之旅。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AWS系列之一 亚马逊云服务概述]]></title>
    <link href="http://www.huangbowen.net/blog/2014/07/11/aws-overview/"/>
    <updated>2014-07-11T17:50:26+10:00</updated>
    <id>http://www.huangbowen.net/blog/2014/07/11/aws-overview</id>
    <content type="html"><![CDATA[<p>云计算经过这几年的发展，已经不再是是一个高大上的名词，而是已经应用到寻常百姓家的技术。每天如果你和互联网打交道，那么或多或少都会和云扯上关系。gmail、github、各种网盘、GAE、heroku等各种服务都属于云服务的范畴。那么云计算的定义到底是什么？这里有摘自wiki的定义。</p>

<!-- more -->


<blockquote><blockquote><p>Cloud computing in general can be defined as a computer network which includes, computing hardware machine or group of computing hardware machines commonly referred as a server or servers connected through a communication network such as the Internet, an intranet, a local area network(LAN) or wide area network(WAN).</p></blockquote></blockquote>

<p>从上面的定义可以看出，云计算可以看做一个计算网络，其由一组硬件主机作为服务器，然后通过通讯网络连接，从而给其他用户提供各种各样的服务。</p>

<p>以下是云计算的一个概念图。</p>

<p>{% img /images/cloudComputer.png  800 %}</p>

<p>从该图中可以看出，云计算提供的服务可以分为三层，第一层是基础设施（Infrastructure）,第二层是平台（Platform）,第三层是应用软件（Application）。基础设置的服务包括虚拟或实体计算机、块级存储、网络设施（如负载均衡，内容交付网络，DNS解析）等，平台的服务包括对象存储、认证服务和访问服务、各种程序的运行时、队列服务、数据库服务等，而应用软件的服务则包括的多了，比如邮件服务、代码托管服务等等。用户可以通过台式电脑、手提电脑、手机、平板等各种互联网终端设备访问和使用这些服务。</p>

<p>其实这三层就是我们常说的IaaS（Infrastructure as a Service）、PaaS（Platform as a Service）、SaaS(Software as a Service)。</p>

<p>{% img /images/cloudService.png 800 %}</p>

<p>亚马逊的云服务提供了多达几十种服务，涵盖了IaaS、PaaS、SaaS这三层。既然是亚马逊云服务，那么为什么通常都叫做Amazon Web Service（AWS）那，为什么不叫Amazon Cloud Service之类的那？这个就不得而知了，估计当时AWS第一个服务出来的时候是2006年，那时候云的概念还没有这么火，而web service则如日中天，所以起了个这个名字。好了不八卦了，先看看亚马逊云计算的架构图。</p>

<p>{% img /images/awsstructure.png 800 %}</p>

<p>从该架构图可以看出，亚马逊云服务由7部分组成。接下来对这7部分的主要服务做一个简要的介绍。</p>

<h2>AWS Global Infrastructure(AWS 全局基础设施)</h2>

<p>在全局基础设施中有3个很重要的概念。第一个是Region（区域），每个Region是相互独立的，自成一套云服务体系，分布在全球各地。目前全球有10个Region，北京的Region已经在内测当中，不久就会开放使用。</p>

<p>第二个是Availability Zone(可用区)，每个Region又由数个可用区组成，每个可用区可以看做一个数据中心，相互之间通过光纤连接。</p>

<p>第三个是Edge Locations（边缘节点）。全球目前有50多个边缘节点，是一个内容分发网络（CDN，Content Distrubtion Network），可以降低内容分发的延迟，保证终端用户获取资源的速度。它是实现全局DNS基础设施（Route53）和CloudFront CDN的基石。</p>

<h2>Networking（网络）</h2>

<p>AWS提供的网络服务主要有：</p>

<ul>
<li><p>Direct Connect： 支持企业自身的数据中心直接与AWS的数据中心直连，充分利用企业现有的资源。</p></li>
<li><p>VPN Connection：通过VPN连接AWS，保证数据的安全性。</p></li>
<li><p>Virtual Private Cloud： 私有云，从AWS云资源中分一块给你使用，进一步提高安全性。</p></li>
<li><p>Route 53：亚马逊提供的高可用的可伸缩的域名解析系统。</p></li>
</ul>


<h2>Compute（计算）</h2>

<p>这可是亚马逊的计算核心，包括了众多的服务。</p>

<ul>
<li><p>EC2： Elastic Computer service,亚马逊的虚拟机，支持Windows和Linux的多个版本，支持API创建和销毁，有多种型号可供选择，按需使用。并且有auto scaling功能，有效解决应用程序性能问题。</p></li>
<li><p>ELB： Elastic Load Balancing， 亚马逊提供的负载均衡器，可以和EC2无缝配合使用，横跨多个可用区，可以自动检查实例的健康状况，自动剔除有问题的实例，保证应用程序的高可用性。</p></li>
</ul>


<h2>Storage（存储）</h2>

<ul>
<li><p>S3： Simple Storage Service，简单存储服务，是亚马逊对外提供的对象存储服务。不限容量，单个对象大小可达5TB，支持静态网站。其高达99.999999999%的可用性让其它竞争对手胆寒。</p></li>
<li><p>EBS： Elastic Block Storage，块级存储服务，支持普通硬盘和SSD硬盘，加载方便快速，备份非常简单。</p></li>
<li><p>Glacier：主要用于较少使用的存储存档文件和备份文件，价格便宜量又足，安全性高。</p></li>
</ul>


<h2>Database（数据库）</h2>

<p>亚马逊提供关系性数据库和no sql数据库，以及一些cache等数据库服务。</p>

<ul>
<li><p>DynamoDB： DynamoDB是亚马逊自主研发的no sql型数据库，性能高，容错性强，支持分布式，并且与Cloud Watch、EMR等其它云服务高度集成。</p></li>
<li><p>RDS： Relational Database Service，关系型数据库服务。支持MySql，SQL Server和Oracle等数据库，具有自动备份功能，IO吞吐量可按需调整。</p></li>
<li><p>Amazon ElastiCache： 数据库缓存服务。</p></li>
</ul>


<h2>Application Service（应用程序服务）</h2>

<p>这里的服务可就多了。</p>

<ul>
<li><p>Cloud Search: 一个弹性的搜索引擎，可用于企业级搜索。</p></li>
<li><p>Amazon SQS： 队列服务，存储和分发消息。</p></li>
<li><p>Simple Workflow：一个工作流框架。</p></li>
<li><p>CloudFront：世界范围的内容分发网络。</p></li>
<li><p>EMR： Elastic MapReduce，一个hadoop框架的实例，可用于大数据处理。</p></li>
</ul>


<h2>Deployment &amp; Admin (部署和管理)</h2>

<ul>
<li><p>Elastic BeanStalk: 一键式创建各种开发环境和运行时。</p></li>
<li><p>CloudFormation：采用jason格式的模板文件来创建和管理一系列亚马逊云资源。</p></li>
<li><p>OpsWorks： OpsWorks允许用户将应用程序的部署模块化，可以实现对数据库、运行时、服务器软件等自动化设置和安装。</p></li>
<li><p>IAM： Identity &amp; Access Management，认证和访问管理服务。用户使用云服务最担心的事情之一就是安全问题。亚马逊通过IAM提供了立体化的安全策略，保证用户在云上的资源绝对的安全。用户通过IAM可以管理对AWS资源的访问。通过IAM可以创建group和role来授权或禁止对各种云资源的访问。</p></li>
</ul>


<p>如果想获取更多知识可以访问亚马逊AWS的官网<a href="http://aws.amazon.com/">http://aws.amazon.com/</a>。如果想查看每个服务的详细信息，可以查看它们的官方文档<a href="https://aws.amazon.com/documentation/?nc1=h_su_dm">https://aws.amazon.com/documentation/?nc1=h_su_dm</a>。还有亚马逊的所有云服务都提供了API接口进行调用，并且提供了命令行工具Amazon CLI（Command Line Interface）来使用，详细信息请参见<a href="http://docs.aws.amazon.com/cli/latest/index.html">http://docs.aws.amazon.com/cli/latest/index.html</a>。</p>

<p>另外，亚马逊提供了一个网址用于练习对AWS服务的使用。地址是<a href="https://run.qwiklabs.com">https://run.qwiklabs.com</a>,还没有申请AWS账号的同学有福了，里面有6节免费的课程，可以根据提示一步步操作AWS资源，并且消耗的资源都是免费的。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[成都亚马逊AWSome Day回顾]]></title>
    <link href="http://www.huangbowen.net/blog/2014/07/07/awsome-day-memo/"/>
    <updated>2014-07-07T15:54:42+10:00</updated>
    <id>http://www.huangbowen.net/blog/2014/07/07/awsome-day-memo</id>
    <content type="html"><![CDATA[<p>昨天我和公司同仁一起参加了亚马逊在成都的第一场AWSome Day活动。整个活动时间异常紧促，短短一天包含了7堂session，讲师的狂轰乱炸使得我们同学们普遍觉得比上班累多了。好了，废话不多说，让我们来回顾一下昨天都讲了那些东西。</p>

<!-- more -->


<p>第一个session主题是AWS技术推动的创新。听名称就知道给亚马逊云服务打广告了。里面讲述了AWS各种服务的牛逼，讲师说AWS计算量=其余15家云计算平台总计算量 * 5。是不是吹牛不得而知了。还有一点是AWS自从2006年发布以来经历了43次主动降价。就我个人使用AWS服务而言，感觉价格还是挺公道的。我的个人博客使用了AWS的Route53，S3，CloudFrond等服务，一个月收费也不过1刀多。这个session一句话来总结就是我们最牛B，其它的都是渣渣。当然亚马逊讲师这样说毕竟还是有一定底气的。</p>

<p>第二个session主题是AWS服务概览。讲师带领我们对AWS的服务做了一个整体回顾。其计算服务主要包括EC2，存储服务包括S3，EBS，Glacier。数据库服务包括Redshift，DynamoDB，RDS，ElasticCache。部署与自动化服务包括CloudFormation，BeanStalk，OpsWorks。认证与访问服务IAM。网络服务VPC，Route53，ELB，Direct Connect。分布式计算服务包括Amazon EMR, Auto Scaling。内容传输服务CloudFront。大家看到这里是不是有点头晕了？</p>

<p>第三个session主题是AWS存储服务。讲师仔细介绍了S3，EBS，Glacier三种存储服务的不同与适用场景。S3的容灾率最高，可用性最高，并且每个存储文件附带一个url，可以直接访问。EBS价格公道，需要配合S3或EC2来访问使用。而Glacier相当于存档文件，可以保存10年以上，价格最低。如果你上存储的数据大于1TB，甚至PB级别，亚马逊还贴心的提供了数据Import/Export服务，那速度是杠杠的，可以达到几十GB的传输速率。那么亚马逊是如何达到这样的带宽那？方法是你把你的硬盘邮寄给亚马逊数据中心，亚马逊数据中心直接外挂你的硬盘进行数据导入。</p>

<p>吃了免费的午餐，下午的一大波session又来袭了。</p>

<p>下午第一场session是关于AWS计算服务和网络。讲师介绍了最常用的EC2服务，还有用于大数据分析和挖掘的EMR系统。并且顺带讲述了CloudFront，Rout53，ELB等是如何协作来提供网络应用程序的访问速度的。还有亚马逊那神奇的Auto Scalling技术。安全是云服务的重中之重。亚马逊采用了IAM来统一管理和分配对云上的资源的各种访问。用户可以创建用户名和密码，创建access key，创建用户组等多种方式来控制对各种资源的访问。亚马逊也提供了VPC和路由机制来实现公网和私有局域网的的隔离和访问。</p>

<p>第二场session是关于AWS管理的服务和数据库。亚马逊提供DynamoDB，RDS，Redshift，ElasticCache等与数据库有关的服务。其中DynamoDB是亚马逊自护研发的no sql数据库系统，自然少不了一番大吹特吹。RDS数据库支持mysql，Oracle，sql server等。这些数据库服务都支持自动备份，每隔5分钟备份一次，备份文件可保存0-35天。用户也可以手动备份，将备份文件放置到S3中永久保存。Redshift是亚马逊提供的数据仓库服务，可帮助你使用现有的商业智能工具进行大数据分析和处理。ElasticCache是亚马逊内置的缓存服务，DynamoDB，RDS数据库都可使用，可有效提高数据库吞吐量。</p>

<p>第三场session是AWS的部署和管理。CloudWacth可以检测云上的资源，并根据配置的policy来自动进行scale out和scale in。比如如果CloudWatch发现EC2实例的cpu占用率在90%以上并保持5分钟，则会自动setup新的EC2服务器并注册到ELB上。使用的好的话运维人员再也不同半夜从床上爬起来解决问题了。而CloudFormation，Elastic Beanstalk，OpsWorks都是DevOps工具箱中不可缺少的工具，如果要实现inforstructure as code，这些工具可助你一臂之力。</p>

<p>最后一个session是AWS解决方案参考架构概览。这里主要说明了你的应用程序如果要放到云上，在设计架构的时候需要遵守一定的准则，否则无法使用到云的优势，结果适得其反。比如AWS提供给你菜刀切肉，水果刀切水果。你偏偏拿个水果刀切肉还直吆喝着不好使，那就不对了。总之一句话，架构设计时一定要SOA，SOA，SOA。</p>

<p>OK，大概内容就是这样了。听了以后是不是想亲自动手。什么？还有没有AWS账号？什么？还没有信用卡？什么？不知道哪里有详细的学习文档？</p>

<p>统统忘掉这些吧。AWS祭出了神器：<a href="https://run.qwiklabs.com">https://run.qwiklabs.com</a>。这是一个用于学习和演练亚马逊各种服务的实验室，只需花一分钟注册即可使用。里面有各种服务的详细操作文档，并且支持真实演练。当你选择一堂课后，qwiklabs会自动给你生成一个AWS账号，你可以使用该账号登陆到真实的亚马逊云服务终端中进行各种破坏而不花费你一毛钱。想当年我自己play with AWS各种云服务时可没少花冤枉钱。</p>

<p>熟悉了亚马逊云，学习其它云还不是小菜一碟。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[将我的博客迁移到亚马逊云端(1)]]></title>
    <link href="http://www.huangbowen.net/blog/2013/09/30/migrate-octopress-to-aws/"/>
    <updated>2013-09-30T14:09:00+10:00</updated>
    <id>http://www.huangbowen.net/blog/2013/09/30/migrate-octopress-to-aws</id>
    <content type="html"><![CDATA[<p>{% img /images/cloudcompute.png 400 %}</p>

<p><a href="http://octopress.org/">Octopress</a>已经被公认为Geeker的博客框架。它所拥有的特性都很符合Geeker的癖好:强大的命令行操作方式、简洁的MarkDown语法、灵活的插件配置、美轮美奂的theme（自带响应式设计哦）、完全可定义的部署&hellip;&hellip;</p>

<p>一般大家都喜欢把博客部署到github pages上，免费速度快，与<a href="http://octopress.org/">Octopress</a>无缝结合。但是自己最近迷上了AWS，就捉摸着将自己的<a href="http://octopress.org/">Octopress</a>博客部署到AWS的S3上，使用CloudFront做CDN，使用Amazon Route 53做域名映射。倒腾了两天，终于搞定了，也学到了很多东西。不敢私藏，拿出来和大家分享。</p>

<!-- more -->


<p>这篇文章主要讲如何将Octopress博客部署到S3上去。下一篇文章会讲如何将CloudFront做CDN,并与现有域名绑定。</p>

<p>在此之前先普及一些概念。</p>

<p>AWS - Amazon Web Service,亚马逊提供的云服务简称。</p>

<p>S3 - Amazon Simple Storage Service, 亚马逊提供的一种存储静态资源（如css、js、html文件，音视频文件）的服务。</p>

<p>CDN - Content Delivery Network, 内容分发网络。</p>

<p>Amazon CloudFront - 亚马逊提供的一种内容分发服务，提高你的网站访问速度。</p>

<p>Amazon Route 53 - 亚马逊提供的一种稳定高效的域名解析系统。</p>

<p>第一步，注册一个亚马逊的账号，注册地址是<a href="https://portal.aws.amazon.com/gp/aws/developer/registration/index.html">https://portal.aws.amazon.com/gp/aws/developer/registration/index.html</a>。注意注册的时候需要提供一张具备外币功能的信用卡。</p>

<p>第二步，登陆到Amazon management console里，单击右上角的名称，选择Security Credentials标签，然后点击左侧标签按照向导创建一个group,一个从属于这个group的user，并为该user生成一个Access key，记录下来Access key Id 及 Secret Access Key。亚马逊的文档还是非常详细的，不懂的可以多看看提示信息和帮助文档。</p>

<p>第三步，在Amazon management console里选择Services -> S3 service，并创建两个bucket。假如你的博客域名为example.com，那么两个bucket的名称分别为example.com,www.example.com。为什么要创建两个那？是因为我们要保证用户无论输入www.example.com还是example.com都可以访问我们的网站。</p>

<p>{% img /images/twobucket.png 780 %}</p>

<p>第四步，选择www.example.com这个bucket，点击properties标签，在Static Website Hosting中选择Redirect all requests to another host name，并配置‘Redirect all requests to:’为example.com。这样来自www.example.com bucket的访问都会自动转发给example.com这个bucket。我们只需为example.com这个bucket同步我们的博客文件即可。</p>

<p>{% img /images/redirectrequest.png 780 %}</p>

<p>第五步，选择example.com这个bucket，在Static Website Hosting中选择‘Enable Website Hosting’,并配置Index Document，我的是index.html。这个Index Document是默认返回的object名称。比如如果用户直接访问bucket的某个目录，系统会检测该目录下是否存在Index Document中配置的文件名，如果有则会自动返回这个object。</p>

<p>{% img /images/staticwebsitehosting.png 780 %}</p>

<p>第六步，选择'Permissions'标签，点击’add bucket policy‘按钮，加入如下的policy.</p>

<pre><code class="javascript">
{
     "Version": "2008-10-17",
     "Statement": [
          {
               "Sid": "AddPerm",
               "Effect": "Allow",
               "Principal": {
                    "AWS": "*"
               },
               "Action": "s3:GetObject",
               "Resource": "arn:aws:s3:::example.com/*"
          }
     ]
}
</code></pre>

<p>这个policy其实是给所有匿名用户访问该bucket里面文件的权限。</p>

<p>{% img /images/bucketpolicy.png 780 %}</p>

<p>第七步，还是在’Permissions‘标签里，点击’Add CORS configuration‘按钮，加入如下的配置：</p>

<pre><code class="xml">
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;CORSConfiguration xmlns="http://s3.amazonaws.com/doc/2006-03-01/"&gt;
    &lt;CORSRule&gt;
        &lt;AllowedOrigin&gt;*&lt;/AllowedOrigin&gt;
        &lt;AllowedMethod&gt;GET&lt;/AllowedMethod&gt;
        &lt;MaxAgeSeconds&gt;3000&lt;/MaxAgeSeconds&gt;
        &lt;AllowedHeader&gt;Authorization&lt;/AllowedHeader&gt;
    &lt;/CORSRule&gt;
&lt;/CORSConfiguration&gt;
</code></pre>

<p>这个是用来配置跨域访问的权限，即是否允许其他网站访问这个bucket上的资源。由于Octopress博客集成了很多插件，比如google analiycis, github等，都需要跨域加载JavaScript文件，执行JavaScript文件，所以要加入这些配置。</p>

<p>{% img /images/corsconfiguration.png 780 %}</p>

<p>第八步，下载安装<a href="http://s3tools.org/s3cmd">s3cmd</a>。<a href="http://s3tools.org/s3cmd">s3cmd</a>是一款操作AWS S3的命令行工具。通过它可以创建或删除bucket，上传或下载object，我们在部署octopress博客时，主要就是通过它来将博客上传到S3上去。如果是mac系统化可以通过HomeBrew直接安装。</p>

<pre><code class="bash">
# brew install s3cmd
</code></pre>

<p>如果是windows系统可以从<a href="http://s3tools.org/s3cmd">官网</a>下载安装包进行安装。</p>

<p>第九步，配置<a href="http://s3tools.org/s3cmd">s3cmd</a>与你的S3的连接。在命令行下输入<code>s3cmd --configure</code>，按照向导来配置与S3的连接。这时候在前面保存的Access key就派上用场了。所有的配置信息其实都存在当前用户名下的.s3cfg文件中。你也可以随后修改这些信息。运行<code>s3cmd ls</code>来检测是否配置成功。</p>

<pre><code class="bash">
$ s3cmd ls #列出所有的bucket
2013-09-27 05:05  s3://huangbowen.net
2013-09-28 03:24  s3://www.huangbowen.net
</code></pre>

<p>第十步，配置Octopress支持向S3的部署。在Octopress目录下找到Rakefile文件，修改或添加下述配置。</p>

<pre><code class="xml">
deploy_default = "s3"   #部署task
s3_bucket = "example.com" # bucket名称

s3_cache_secs = 3600  # header中的cache controll属性，即缓存时间，后面CloudFront要用到
</code></pre>

<p>然后添加一个新的task。</p>

<pre><code class="ruby">
desc "Deploy website via s3cmd"
task :s3 do
  puts "## Deploying website via s3cmd"
  ok_failed system("s3cmd sync --acl-public --reduced-redundancy --add-header \"Cache-Control: max-age=#{s3_cache_secs}\"  public/* s3://#{s3_bucket}/")
end
</code></pre>

<p>OK，大功告成，运行<code>rake generate</code>
及<code>&amp;&amp; rake deploy</code>就可以将生成的静态站点上传到S3中区。然后就可以通过S3的EndPoint来访问新站点了。（EndPoint可以在Amazon management console的S3 dashboard的
‘Static Website Hosting’ 标签中找到）</p>

<p>当然现在还不能使用自己的域名来访问，你可以通过配置CNAME来启用自己的域名。</p>

<p>下篇文章会讲如何将CloudFront作为内容分发，并且如何将自己的域名与CloudFront绑定。</p>

<p>现在我的博客已经在云端了，地址是<a href="http://www.huangbowen.net">http://www.huangbowen.net</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[云时代基础设置自动化管理利器： Chef]]></title>
    <link href="http://www.huangbowen.net/blog/2013/09/16/introduction-of-chef/"/>
    <updated>2013-09-16T23:29:00+10:00</updated>
    <id>http://www.huangbowen.net/blog/2013/09/16/introduction-of-chef</id>
    <content type="html"><![CDATA[<p>{% img /images/migrate_to_cloud.png %}</p>

<p>云时代的到来势不可挡。尤其作为程序员，我们每天或多或少的直接或间接的使用者各种云服务。云平台有很多种，如云软件（SaaS， Software as a service）、云平台（PaaS, Platform as a service）、云设备(IaaS, Infrastructure as a service)。云计算由于其价格低廉、按需提高、使用方便等特点，越来越受到人们的欢迎。</p>

<!-- more -->


<h2>Chef是什么？</h2>

<p>Chef的出现正是顺应了云潮流。如果你是一个公司的devops成员，每天配置服务器上的软件和服务，为了给服务器新加一个节点而通宵作业，为了解决服务器上的一个奇诡问题而想破脑袋。
这时候，你应该考虑使用Chef。</p>

<blockquote><p>Chef is built to address the hardest infrastructure challenges on the planet. By modeling IT infrastructure and application delivery as code, Chef provides the power and flexibility to compete in the digital economy.</p></blockquote>

<p>通过这段话，可以总结出Chef的几个特点。</p>

<ol>
<li><p>Chef是为了解决基础设施难题。</p></li>
<li><p>Chef通过建模将基础设施及应用程序交付抽象为代码。</p></li>
<li><p>Chef具有强大的能力及灵活性.</p></li>
<li>由于配置即代码，基础设施即代码，Chef自动具有了版本控制功能，同时添加复制服务器也变得更容易。</li>
</ol>


<p>Chef主要包括三大块：Workstation、Chef Server、Chef Client。（另外还有个chef-solo，是个简化版的Chef-Client，不在本文讨论范围。）</p>

<p>以下是Chef的架构图。</p>

<p>{% img /images/chef_overview.png 600 %}</p>

<h2>Workstation</h2>

<p>Workstation可以简单地认为是自己的工作电脑，在上面需要建立一个chef-repo。chef-repo管理了cookbooks、recipes、roles、environment等数据。cookbooks、recipes、roles是Chef对infrastructure做的一层抽象。可以打个这样的比喻，cookbooks可以理解为一个菜系，recipes就是这个菜系里面的一道道菜，比如宫保鸡丁，roles则是一桌丰富的宴席，比如满汉全席。而nodes则是一个个盛菜的桌子。我们可以来一个满汉全席（直接给这个node设置一个role），也可以从菜系里抽一些菜品来做一到家常小菜（给指定node设置一个run list，里面包括指定的recipe）。recipe就是一系列的资源，比如在node上需要安装jvm，那么安装jvm的包就是一个recipe。</p>

<p>在Workstation上主要通过knife这个命令行工具来创建和管理这些资源。</p>

<pre><code class="bash ">
$ knife help list
Available help topics are:
  bootstrap
  chef-shell
  client
  configure
  cookbook
  cookbook-site
  data-bag
  environment
  exec
  index
  knife
  node
  role
  search
  shef
  ssh
  status
  tag
</code></pre>

<p>knife是由ruby写的一个gem。它的API很有表现力。</p>

<pre><code class="bash ">
# 创建一个recipe
$ knife cookbook create myRecipe
** Creating cookbook myRecipe
** Creating README for cookbook: myRecipe
** Creating CHANGELOG for cookbook: myRecipe
** Creating metadata for cookbook: myRecipe

#从cookbook server上下载recipe
$ knife cookbook site install apache2

#将本地的recipe上传到服务器上
$ knife cookbook upload myRecipe


#查看服务上当前注册的所有的node
$ knife node list
bowenhuang-starter 

#查看bowenhuang-starter node的详细信息
$ knife node show bowenhuang-starter
Node Name:   bowenhuang-starter
Environment: _default
FQDN:        bowenhuang-starter
IP:          10.0.2.15
Run List:    recipe[apt], recipe[apache2]
Roles:
Recipes:     apt, apache2
Platform:    ubuntu 12.04
Tags:

#将指定IP或主机名的机器注册到服务器上
$ knife bootstrap IP \
  --ssh-user USERNAME \
  --ssh-password PASSWORD \
  --ssh-port PORT \
  --sudo
</code></pre>

<p>在cehf-repo下需要建立一个隐藏的文件夹.chef，该文件夹中包含三个重要的文件：USER.pem, ORGANIZATION-validator.pem, knife.rb。USER.pem是一个私钥，用于workstation与chef server通讯。ORGANIZATION-validator.pem是另一个私钥，用于bootstrap一个新node时该node第一次与服务器通讯。knife.rb则是knife的配置的文件，比如客户端key文件路径，chef server的api地址，cookbook的路径等。</p>

<h2>Chef Server</h2>

<p>Chef Server用来存储workstaton上传的各种资源，包括cookbooks，roles，environments，nodes等。我们可以使用公有的Server，如opscode,也可以通过开源软件架设自己的私服。Chef server提供了一系列的api，用于与workstation和nodes传输资源和数据。opscode上的server需要注册，注册以后需要建立一个organisation, 并从server上下载生成的USER.pem私钥和ORGANISATION-validitor.pem私钥。Chef server也提供了一个search的API，可以通过workstation根据attributes检索注册在服务器上的node。</p>

<p>Chef Server本来是使用ruby写的，后来为了保持高并发和稳定性，能够同时服务一定数量级的node，Chef Server内核采用了支持高并发的Erlang程序，而前端则仍然使用ruby on rails。</p>

<h2>Nodes</h2>

<p>在bootstrap一个node时候，首先需要在该node上安装chef-client包，并将workstation上的ORGANIZATION-validator.pem文件拷贝到node节点上，供node与chef server建立连接。chef server通过验证后会发给node一个新的私钥，以后node就可以通过这个新的私钥与chef server交互。在node的<code>etc\chef</code>的目录下会生成四个文件：client.pem, client.rb, first-boot.json, validation.pem。vlidation.pem就是从workstation拷贝过来的秘钥，client.pem则是服务器为该node新生成的秘钥，client.rb则定义了服务器的API地址，秘钥文件路径等信息，first-boot.json则存放了bootstrap该node节点时的配置信息，如run list信息，role信息等。</p>

<p>chef-client是一个可定期的后台运行的命令行程序。chef-client会收集当前node的各种信息，如操作信息型号版本等，和chef server建立连接，获取chef server上对该节点的配置信息，并安装指定的recipe，运行指定的服务。</p>

<hr />

<p>通过Chef，可以一键更新所有的服务器，在指定的服务器上安装指定的软件。如果有新同事入职，可以很轻松的setup一台开发机；如果服务器节点需要扩展，也只需要几个命令就可搞定。运筹帷幄，一切皆在掌控之中。</p>
]]></content>
  </entry>
  
</feed>
